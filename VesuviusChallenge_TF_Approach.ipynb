{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2feef704",
   "metadata": {},
   "source": [
    "# Keras Starter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0779e27",
   "metadata": {},
   "source": [
    "### Full training set, UNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7a9e901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup Complete\n",
      "Num GPUs Available:  1\n",
      "Name: Quadro RTX 3000\n",
      "WARNING:tensorflow:From C:\\Users\\PAPATELH\\AppData\\Local\\Temp\\ipykernel_631512\\2683020196.py:29: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n",
      "Version:  2.10.0\n",
      "Eager mode:  True\n",
      "GPU is available\n",
      "Sat Apr  1 12:53:40 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.27       Driver Version: 527.27       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 3000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   68C    P2    32W /  N/A |    204MiB /  6144MiB |      3%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     23636    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A    230604      C   C:\\NLP_Heat\\Py\\python.exe       N/A      |\n",
      "|    0   N/A  N/A    631512      C   C:\\NLP_Heat\\Py\\python.exe       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Setup, importing required libraries \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "import PIL.Image as Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import os\n",
    "print('Setup Complete')\n",
    "\n",
    "#Checking Version and usage of GPU\n",
    "tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "gpu_devices = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpu_devices:\n",
    "        # Get details of the GPU\n",
    "        details = tf.config.experimental.get_device_details(gpu)\n",
    "        # Print GPU name\n",
    "        print(f\"Name: {details['device_name']}\")\n",
    "        tf.config.experimental.get_memory_info('GPU:0')\n",
    "\n",
    "tf.test.is_gpu_available(\n",
    "  cuda_only=False, min_cuda_compute_capability=None\n",
    ")\n",
    "\n",
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n",
    "\n",
    "#GPU Info if it is Nvidia\n",
    "def get_gpu_info():\n",
    "    try:\n",
    "        nvidia_smi_output = subprocess.check_output(['nvidia-smi']).decode('utf-8')\n",
    "        print(nvidia_smi_output)\n",
    "    except FileNotFoundError:\n",
    "        print(\"nvidia-smi command not found. Make sure the NVIDIA System Management Interface is installed.\")\n",
    "    except subprocess.CalledProcessError:\n",
    "        print(\"An error occurred while running the nvidia-smi command.\")\n",
    "\n",
    "get_gpu_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb838a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
