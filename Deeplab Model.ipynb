{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da3fa664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Apr  1 12:59:02 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 527.27       Driver Version: 527.27       CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Quadro RTX 3000    WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   68C    P8     7W /  N/A |      0MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     23636    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "|    0   N/A  N/A    230604      C   C:\\NLP_Heat\\Py\\python.exe       N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bfccb9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.segmentation.deeplabv3 import DeepLabHead\n",
    "from torchvision import models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def create_model(in_ch):\n",
    "    model = models.segmentation.deeplabv3_resnet101(pretrained=False,\n",
    "                                                    progress=False, weights=None, weights_backbone=None)\n",
    "    model.load_state_dict(torch.load('/kaggle/input/deeplabv3-pretrained/deeplabv3_pretrained.pt'))\n",
    "    model.backbone.conv1 = nn.Conv2d(in_ch, 64, 7, 2, 3, bias=False)\n",
    "\n",
    "    model.classifier = DeepLabHead(2048, 1)\n",
    "    # Set the model in training mode\n",
    "    model.train()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9c8ed286",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(pred, target, smooth = 1.):\n",
    "    pred = pred.contiguous()\n",
    "    target = target.contiguous()    \n",
    "\n",
    "    intersection = (pred * target).sum(dim=2).sum(dim=2)\n",
    "    \n",
    "    loss = (1 - ((2. * intersection + smooth) / (pred.sum(dim=2).sum(dim=2) + target.sum(dim=2).sum(dim=2) + smooth)))\n",
    "    \n",
    "    return loss.mean()\n",
    "\n",
    "def calc_loss(pred, target, bce_weight = 1):\n",
    "    bce = F.binary_cross_entropy_with_logits(pred, target)\n",
    "\n",
    "    pred = F.sigmoid(pred)\n",
    "    dice = dice_loss(pred, target)\n",
    "\n",
    "    loss = bce * bce_weight + dice * (1 - bce_weight)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3d818a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import PIL.Image as Image\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# ================== random patch dataset ==============================\n",
    "class RandomOpt():\n",
    "    def __init__(self):\n",
    "        self.SHARED_HEIGHT = 4096  # Height to resize all papyrii\n",
    "        self.BUFFER = 64  # Half-size of papyrus patches we'll use as model inputs\n",
    "        self.Z_DIM = 16  # Number of slices in the z direction. Max value is 64 - Z_START\n",
    "        self.Z_START = 25  # Offset of slices in the z direction\n",
    "        self.DATA_DIR = \"/kaggle/input/vesuvius-challenge-ink-detection\"\n",
    "\n",
    "def resize(img, SHARED_HEIGHT=RandomOpt().SHARED_HEIGHT):\n",
    "    current_width, current_height = img.size\n",
    "    aspect_ratio = current_width / current_height\n",
    "    new_width = int(SHARED_HEIGHT * aspect_ratio)\n",
    "    new_size = (new_width, SHARED_HEIGHT)\n",
    "    img = img.resize(new_size)\n",
    "    return img\n",
    "\n",
    "\n",
    "def load_mask(split, index, DATA_DIR=RandomOpt().DATA_DIR):\n",
    "    img = Image.open(f\"{DATA_DIR}/mask.png\").convert('1')\n",
    "    img = resize(img)\n",
    "    return torch.from_numpy(np.array(img))\n",
    "\n",
    "def load_labels(split, index, DATA_DIR=RandomOpt().DATA_DIR):\n",
    "    img = Image.open(f\"{DATA_DIR}/inklabels.png\")\n",
    "    img = resize(img)\n",
    "    return torch.from_numpy(np.array(img)).gt(0).float()\n",
    "\n",
    "def load_volume(split, index, DATA_DIR=RandomOpt().DATA_DIR, Z_START=RandomOpt().Z_START, Z_DIM=RandomOpt().Z_DIM):\n",
    "    # Load the 3d x-ray scan, one slice at a time\n",
    "    z_slices_fnames = sorted(glob.glob(f\"{DATA_DIR}/{split}/{index}/surface_volume/*.tif\"))[Z_START:Z_START + Z_DIM]\n",
    "    print(f\"Number of files found: {len(z_slices_fnames)}\")  # Add this line to print the number of files found\n",
    "    z_slices = []\n",
    "    for z, filename in  tqdm(enumerate(z_slices_fnames)):\n",
    "        img = Image.open(filename)\n",
    "        img = resize(img)\n",
    "        z_slice = np.array(img, dtype=\"float32\")\n",
    "        z_slices.append(torch.from_numpy(z_slice))\n",
    "    return torch.stack(z_slices, dim=0)\n",
    "\n",
    "# Random choice of patches for training\n",
    "def sample_random_location(shape, BUFFER=RandomOpt().BUFFER):\n",
    "    a=BUFFER\n",
    "    random_train_x = (shape[0] - BUFFER - 1 - a)*torch.rand(1)+a\n",
    "    random_train_y = (shape[1] - BUFFER - 1 - a)*torch.rand(1)+a\n",
    "    random_train_location = torch.stack([random_train_x, random_train_y])\n",
    "    return random_train_location\n",
    "\n",
    "def is_in_masked_zone(location, mask):\n",
    "    return mask[location[0].long(), location[1].long()]\n",
    "\n",
    "def is_in_val_zone(location, val_location, val_zone_size, BUFFER=RandomOpt().BUFFER):\n",
    "    x = location[0]\n",
    "    y = location[1]\n",
    "    x_match = val_location[0] - BUFFER <= x <= val_location[0] + val_zone_size[0] + BUFFER\n",
    "    y_match = val_location[1] - BUFFER <= y <= val_location[1] + val_zone_size[1] + BUFFER\n",
    "    return x_match and y_match\n",
    "\n",
    "class RandomPatchLocDataset(data.Dataset):\n",
    "    def __init__(self, mask, val_location, val_zone_size):\n",
    "        self.mask = mask\n",
    "        self.val_location = val_location\n",
    "        self.val_zone_size = val_zone_size\n",
    "        self.sample_random_location_train = lambda x: sample_random_location(mask.shape)\n",
    "        self.is_in_mask_train = lambda x: is_in_masked_zone(x, mask)\n",
    "\n",
    "    def is_proper_train_location(self, location):\n",
    "        return not is_in_val_zone(location, self.val_location, self.val_zone_size) and self.is_in_mask_train(location)\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1280\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Generate a random patch\n",
    "        # Ignore the index\n",
    "        loc = self.sample_random_location_train(0)\n",
    "        while not self.is_proper_train_location(loc):\n",
    "            loc = self.sample_random_location_train(0)\n",
    "        return loc.int().squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b12277b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============= Model ==============\n",
    "class ModelOpt:\n",
    "    def __init__(self):\n",
    "        # self.GPU_ID = '0'  \n",
    "        self.Z_DIM = RandomOpt().Z_DIM\n",
    "        self.BUFFER = RandomOpt().BUFFER\n",
    "        self.SEED = 0\n",
    "        self.BATCH_SIZE = 64\n",
    "        self.LEARNING_RATE =1e-4\n",
    "        self.TRAINING_EPOCH = 25\n",
    "        self.LOG_DIR = '/kaggle/working'\n",
    "        self.LOAD_VOLUME = [1, 2, 3]\n",
    "        # Val\n",
    "        self.VAL_LOC = (1300, 1000)\n",
    "        self.VAL_SIZE = (300, 7000)\n",
    "\n",
    "class RandomPatchModel():\n",
    "    def __init__(self, opt = ModelOpt()):\n",
    "        self.opt = opt\n",
    "        self._setup_all()\n",
    "        self.volume_list = [load_volume('train', i) for i in opt.LOAD_VOLUME]\n",
    "        # Here volume: [Z_DIM, SHARED_HEIGHT, W_V1 + W_V2 + ...]\n",
    "        self.volume = torch.cat(self.volume_list, dim=2)\n",
    "        # Same for mask and label\n",
    "        self.mask_list = [load_mask('train', i) for i in opt.LOAD_VOLUME]\n",
    "        self.labels_list = [load_labels('train', i) for i in opt.LOAD_VOLUME]\n",
    "        # [SHARED_HEIGHT, W_V1 + W_V2 + ...]\n",
    "        self.labels = torch.cat(self.labels_list, dim=1)\n",
    "        self.mask = torch.cat(self.mask_list, dim=1)\n",
    "\n",
    "        self.net = create_model(opt.Z_DIM).to(self.device)\n",
    "\n",
    "        # Dataset\n",
    "        self.loc_datast = RandomPatchLocDataset(self.mask, val_location=opt.VAL_LOC, val_zone_size=opt.VAL_SIZE)\n",
    "        self.loc_loader = data.DataLoader(self.loc_datast, batch_size=opt.BATCH_SIZE)\n",
    "        # Val\n",
    "        self.val_loc = []\n",
    "        for x in range(opt.VAL_LOC[0], opt.VAL_LOC[0] + opt.VAL_SIZE[0], opt.BUFFER):\n",
    "            for y in range(opt.VAL_LOC[1], opt.VAL_LOC[1] + opt.VAL_SIZE[1], opt.BUFFER):\n",
    "                if is_in_masked_zone([torch.tensor(x),torch.tensor(y)], self.mask):\n",
    "                    self.val_loc.append([[x, y]])\n",
    "        print(f\"======> Num Patches Val: {len(self.val_loc)}\")\n",
    "\n",
    "\n",
    "    def _setup_all(self):\n",
    "        # random seed\n",
    "        np.random.seed(self.opt.SEED)\n",
    "        torch.manual_seed(self.opt.SEED)\n",
    "        torch.cuda.manual_seed_all(self.opt.SEED)\n",
    "        # torch\n",
    "        # os.environ['CUDA_VISIBLE_DEVICES'] = self.opt.GPU_ID\n",
    "        torch.backends.cudnn.enabled = True\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        # Log\n",
    "        self.log_dir = self.opt.LOG_DIR\n",
    "        self.ckpt = os.path.join(self.log_dir)\n",
    "\n",
    "    def get_subvolume(self, batch_loc, volume, labels):\n",
    "        # batch_loc : [batch_size, 2]\n",
    "        subvolume = []\n",
    "        label = []\n",
    "        for l in batch_loc:\n",
    "            x = l[0]\n",
    "            y = l[1]\n",
    "            sv = volume[:, x - self.opt.BUFFER:x + self.opt.BUFFER, y - self.opt.BUFFER:y + self.opt.BUFFER]\n",
    "            sv = sv / 65535.\n",
    "            subvolume.append(sv)\n",
    "            if labels is not None:\n",
    "                lb = labels[x - self.opt.BUFFER:x + self.opt.BUFFER, y - self.opt.BUFFER:y + self.opt.BUFFER]\n",
    "                lb = lb.unsqueeze(0)\n",
    "                label.append(lb)\n",
    "        # [batch, Z_DIM, BUFFER, BUFFER]\n",
    "        subvolume = torch.stack(subvolume)\n",
    "        # [batch, 1, BUFFER, BUFFER]\n",
    "        if labels is not None:\n",
    "            label = torch.stack(label)\n",
    "        return subvolume, label\n",
    "\n",
    "    def augment_train_data(self, subvolume, label):\n",
    "        # Add Data augmentation here\n",
    "        return subvolume, label\n",
    "\n",
    "    def train_loop(self):\n",
    "        print(\"=====> Begin training\")\n",
    "#         self.criterion = torch.nn.BCEWithLogitsLoss(reduction='mean')\n",
    "        self.criterion = calc_loss\n",
    "        self.optimizer = optim.Adam(self.net.parameters(), lr=self.opt.LEARNING_RATE)\n",
    "        self.net.train()\n",
    "\n",
    "        best_val_loss = 100\n",
    "        best_val_acc = 0\n",
    "        meter = AverageMeter()\n",
    "        for epoch in range(self.opt.TRAINING_EPOCH):\n",
    "            bar = tqdm(enumerate(self.loc_loader), total=len(self.loc_datast) / self.opt.BATCH_SIZE)\n",
    "            bar.set_description_str(f\"Epoch: {epoch}\")\n",
    "            for i, loc in bar:\n",
    "                subvolume, label = self.get_subvolume(loc, self.volume, self.labels)\n",
    "                loss = self._train_step(subvolume, label)\n",
    "                meter.update(loss)\n",
    "                bar.set_postfix_str(f\"Avg loss: {np.round(meter.get_value(),3)}\")\n",
    "\n",
    "            val_loss, val_acc = self.validataion_loop()\n",
    "            print(f\"======> Val Loss:{np.round(val_loss,3)} | Val Acc:{np.round(val_acc,3)} \")\n",
    "            if val_loss < best_val_loss and val_acc > best_val_acc:\n",
    "                torch.save(self.net.state_dict(), os.path.join(self.ckpt, \"best.pt\"))\n",
    "                print(\"======> Save best val model\")\n",
    "\n",
    "                best_val_loss = val_loss\n",
    "                best_val_acc = val_acc\n",
    "\n",
    "\n",
    "\n",
    "    def _train_step(self, subvolume, label):\n",
    "        self.optimizer.zero_grad()\n",
    "        # inputs: subvolume: [batch, Z_DIM, BUFFER, BUFFER]\n",
    "        #         label: [batch, 1, BUFFER, BUFFER]\n",
    "        outputs = self.net(subvolume.to(self.device))['out']\n",
    "        loss = self.criterion(outputs, label.to(self.device))\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        return loss\n",
    "\n",
    "    def validataion_loop(self):\n",
    "        meter_loss = AverageMeter()\n",
    "        meter_acc = AverageMeter()\n",
    "        self.net.eval()\n",
    "        for loc in self.val_loc:\n",
    "            subvolume, label = self.get_subvolume(loc, self.volume, self.labels)\n",
    "            outputs = self.net(subvolume.to(self.device))['out']\n",
    "            loss = self.criterion(outputs, label.to(self.device))\n",
    "            meter_loss.update(loss)\n",
    "            pred = torch.sigmoid(outputs) > 0.5\n",
    "            meter_acc.update(\n",
    "                (pred == label.to(self.device)).sum(),\n",
    "                int(torch.prod(torch.tensor(label.shape)))\n",
    "            )\n",
    "        self.net.train()\n",
    "        return meter_loss.get_value(), meter_acc.get_value()\n",
    "\n",
    "    def load_best_ckpt(self):\n",
    "        self.net.load_state_dict(torch.load(os.path.join(self.ckpt, \"best.pt\")))\n",
    "\n",
    "\n",
    "# For the metric\n",
    "class AverageMeter(object):\n",
    "    def __init__(self):\n",
    "        self.sum = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def update(self, x, n=1):\n",
    "        self.sum += float(x)\n",
    "        self.n += n\n",
    "\n",
    "    def reset(self):\n",
    "        self.sum = 0\n",
    "        self.n = 0\n",
    "\n",
    "    def get_value(self):\n",
    "        if self.n:\n",
    "            return self.sum / self.n\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16f82a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of files found: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "stack expects a non-empty TensorList",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [31], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mRandomPatchModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn [30], line 21\u001b[0m, in \u001b[0;36mRandomPatchModel.__init__\u001b[1;34m(self, opt)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m opt\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_all()\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume_list \u001b[38;5;241m=\u001b[39m [load_volume(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m, i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mLOAD_VOLUME]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Here volume: [Z_DIM, SHARED_HEIGHT, W_V1 + W_V2 + ...]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn [30], line 21\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mopt \u001b[38;5;241m=\u001b[39m opt\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_all()\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume_list \u001b[38;5;241m=\u001b[39m [\u001b[43mload_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m opt\u001b[38;5;241m.\u001b[39mLOAD_VOLUME]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Here volume: [Z_DIM, SHARED_HEIGHT, W_V1 + W_V2 + ...]\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n",
      "Cell \u001b[1;32mIn [29], line 50\u001b[0m, in \u001b[0;36mload_volume\u001b[1;34m(split, index, DATA_DIR, Z_START, Z_DIM)\u001b[0m\n\u001b[0;32m     48\u001b[0m     z_slice \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(img, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfloat32\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     49\u001b[0m     z_slices\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mfrom_numpy(z_slice))\n\u001b[1;32m---> 50\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz_slices\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: stack expects a non-empty TensorList"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "model = RandomPatchModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f955dd31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
